# Model Explainability

## Introduction
In this section, we will explore the explainability of the model. We will use the following techniques to explain the model for Images:

### 1. Integrated Gradients
### 2. Integrated Gradients with Noise Tunnel
### 3. Gradient SHAP
### 4. Occlusion
### 5. GradCam
### 6. GradCam++
### 7. Saliency
### 8. SHAP

For Text we will use the following techniques:

### 1. SHAP

## Usage:

### To run the explainability of Images:
```bash

python3 main.py

```

### To run the explainability of Text:
```bash
cd src

# Open text_exp.ipynb in Jupyter Notebook and run the cells

```

## Results

### For the results of Images, please refer to the [explainability](EXPLAINABILITY.md) markdown file.
### For the results of Text, please refer to the [notebook](src/text_exp.ipynb).